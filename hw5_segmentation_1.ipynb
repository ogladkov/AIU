{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\sm00th\\AppData\\Local\\conda\\conda\\envs\\tensorflow_gpuenv\\lib\\site-packages\\classification_models\\resnext\\__init__.py:4: UserWarning: Current ResNext models are deprecated, use keras.applications ResNeXt models\n",
      "  warnings.warn('Current ResNext models are deprecated, '\n"
     ]
    }
   ],
   "source": [
    "from segmentation_models import Unet\n",
    "from segmentation_models.backbones import get_preprocessing\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import backend as K\n",
    "from keras.utils import to_categorical\n",
    "K.set_image_data_format('channels_last')\n",
    "from tqdm import tqdm\n",
    "K.clear_session()\n",
    "# from google.colab import drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BACKBONE = 'resnet34'\n",
    "preprocess_input = get_preprocessing(BACKBONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drive.mount('/content/drive')\n",
    "\n",
    "# !unzip drive/My\\ Drive/Colab\\ Notebooks/hw5/dataset1.zip\n",
    "# ! mv dataset1 drive/My\\ Drive/Colab\\ Notebooks/hw5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "IM_WIDTH, IM_HEIGHT = 360, 480\n",
    "RESOLUT = (IM_WIDTH, IM_HEIGHT)\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "# TR_DIR = r'/drive/My\\ Drive/Colab\\ Notebooks/hw5/dataset1/annotations_prepped_train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls drive/My\\ Drive/Colab\\ Notebooks/hw5/dataset1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_prepped_train = r'C:\\Users\\sm00th\\Dropbox\\Python\\Neural Univercity\\hw5\\dataset1\\images_prepped_train'\n",
    "# images_prepped_train = r'drive/My Drive/Colab Notebooks/hw5/dataset1/images_prepped_train'\n",
    "\n",
    "images_prepped_test = r'C:\\Users\\sm00th\\Dropbox\\Python\\Neural Univercity\\hw5\\dataset1\\images_prepped_test'\n",
    "\n",
    "annotations_prepped_train = r'C:\\Users\\sm00th\\Dropbox\\Python\\Neural Univercity\\hw5\\dataset1\\annotations_prepped_train'\n",
    "# annotations_prepped_train = r'drive/My Drive/Colab Notebooks/hw5/dataset1/annotations_prepped_train'\n",
    "\n",
    "annotations_prepped_test = r'C:\\Users\\sm00th\\Dropbox\\Python\\Neural Univercity\\hw5\\dataset1\\annotations_prepped_test'\n",
    "\n",
    "# annotations_prepped_train_list = os.listdir(annotations_prepped_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_ims(path):\n",
    "    ims = []\n",
    "    files = os.listdir(path)\n",
    "    for file in files:\n",
    "        ims.append(plt.imread(os.path.join(path, file)))\n",
    "    ims = preprocess_input(ims)\n",
    "    ims = np.array(ims)\n",
    "    return ims\n",
    "\n",
    "def read_labels(path):\n",
    "    files = os.listdir(path)   \n",
    "    im = np.empty((len(files), 360, 480, 6))\n",
    "    for n, file in enumerate(files):\n",
    "        i = plt.imread(os.path.join(path, file))*255\n",
    "        i = i.astype('int')\n",
    "        i = np.where(i >=5, 5, i)\n",
    "        im[n] = to_categorical(i)\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ims = read_ims(os.path.join(images_prepped_train, 'all'))\n",
    "train_labels = read_labels(os.path.join(annotations_prepped_train, 'all'))\n",
    "test_ims = read_ims(os.path.join(images_prepped_test, 'all'))\n",
    "test_labels = read_labels(os.path.join(annotations_prepped_test, 'all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((367, 360, 480, 3),\n",
       " (367, 360, 480, 6),\n",
       " (101, 360, 480, 3),\n",
       " (101, 360, 480, 6))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ims.shape, train_labels.shape, test_ims.shape, test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = datagen.flow(train_ims, train_labels,\n",
    "                        batch_size=BATCH_SIZE)\n",
    "\n",
    "test_generator = datagen.flow(test_ims, test_labels,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 360, 480, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.next()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 360, 480, 6)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_generator.next()[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet():\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        print ('build UNet ...')\n",
    "\n",
    "\n",
    "\n",
    "    def get_crop_shape(self, target, refer):\n",
    "\n",
    "        # width, the 3rd dimension\n",
    "\n",
    "        cw = (target.get_shape()[2] - refer.get_shape()[2]).value\n",
    "\n",
    "        assert (cw >= 0)\n",
    "\n",
    "        if cw % 2 != 0:\n",
    "\n",
    "            cw1, cw2 = int(cw/2), int(cw/2) + 1\n",
    "\n",
    "        else:\n",
    "\n",
    "            cw1, cw2 = int(cw/2), int(cw/2)\n",
    "\n",
    "        # height, the 2nd dimension\n",
    "\n",
    "        ch = (target.get_shape()[1] - refer.get_shape()[1]).value\n",
    "\n",
    "        assert (ch >= 0)\n",
    "\n",
    "        if ch % 2 != 0:\n",
    "\n",
    "            ch1, ch2 = int(ch/2), int(ch/2) + 1\n",
    "\n",
    "        else:\n",
    "\n",
    "            ch1, ch2 = int(ch/2), int(ch/2)\n",
    "\n",
    "\n",
    "\n",
    "        return (ch1, ch2), (cw1, cw2)\n",
    "\n",
    "\n",
    "\n",
    "    def create_model(self, img_shape, num_class):\n",
    "\n",
    "\n",
    "\n",
    "        concat_axis = 3\n",
    "\n",
    "        inputs = layers.Input(shape = img_shape)\n",
    "\n",
    "\n",
    "\n",
    "        conv1 = layers.Conv2D(32, (3, 3), activation='relu', padding='same', name='conv1_1')(inputs)\n",
    "\n",
    "        conv1 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "\n",
    "        pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "        conv2 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "\n",
    "        conv2 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "\n",
    "        pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "\n",
    "\n",
    "        conv3 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "\n",
    "        conv3 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "\n",
    "        pool3 = layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "\n",
    "\n",
    "        conv4 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
    "\n",
    "        conv4 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
    "\n",
    "        pool4 = layers.MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "\n",
    "\n",
    "        conv5 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
    "\n",
    "        conv5 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
    "\n",
    "\n",
    "\n",
    "        up_conv5 = layers.UpSampling2D(size=(2, 2))(conv5)\n",
    "\n",
    "        ch, cw = self.get_crop_shape(conv4, up_conv5)\n",
    "\n",
    "        crop_conv4 = layers.Cropping2D(cropping=(ch,cw))(conv4)\n",
    "\n",
    "        up6 = layers.concatenate([up_conv5, crop_conv4], axis=concat_axis)\n",
    "\n",
    "        conv6 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
    "\n",
    "        conv6 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
    "\n",
    "\n",
    "\n",
    "        up_conv6 = layers.UpSampling2D(size=(2, 2))(conv6)\n",
    "\n",
    "        ch, cw = self.get_crop_shape(conv3, up_conv6)\n",
    "\n",
    "        crop_conv3 = layers.Cropping2D(cropping=(ch,cw))(conv3)\n",
    "\n",
    "        up7 = layers.concatenate([up_conv6, crop_conv3], axis=concat_axis) \n",
    "\n",
    "        conv7 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
    "\n",
    "        conv7 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
    "\n",
    "\n",
    "\n",
    "        up_conv7 = layers.UpSampling2D(size=(2, 2))(conv7)\n",
    "\n",
    "        ch, cw = self.get_crop_shape(conv2, up_conv7)\n",
    "\n",
    "        crop_conv2 = layers.Cropping2D(cropping=(ch,cw))(conv2)\n",
    "\n",
    "        up8 = layers.concatenate([up_conv7, crop_conv2], axis=concat_axis)\n",
    "\n",
    "        conv8 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n",
    "\n",
    "        conv8 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n",
    "\n",
    "\n",
    "\n",
    "        up_conv8 = layers.UpSampling2D(size=(2, 2))(conv8)\n",
    "\n",
    "        ch, cw = self.get_crop_shape(conv1, up_conv8)\n",
    "\n",
    "        crop_conv1 = layers.Cropping2D(cropping=(ch,cw))(conv1)\n",
    "\n",
    "        up9 = layers.concatenate([up_conv8, crop_conv1], axis=concat_axis)\n",
    "\n",
    "        conv9 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
    "\n",
    "        conv9 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n",
    "\n",
    "\n",
    "\n",
    "        ch, cw = self.get_crop_shape(inputs, conv9)\n",
    "\n",
    "        conv9 = layers.ZeroPadding2D(padding=((ch[0], ch[1]), (cw[0], cw[1])))(conv9)\n",
    "\n",
    "        conv10 = layers.Conv2D(num_class, (1, 1))(conv9)\n",
    "\n",
    "\n",
    "\n",
    "        model = models.Model(inputs=inputs, outputs=conv10)\n",
    "\n",
    "\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_colors = [[np.random.randint(0, 256) for _ in range(3)] for _ in range(6)]\n",
    "\n",
    "def target_preproc(im):\n",
    "    im[:, :] = np.where(im[:, :] >= 5, 6, im[:, :])\n",
    "    \n",
    "    for cl in range(6):\n",
    "        for ch in range(im.shape[2]):\n",
    "            im[:, :, ch] = np.where(im[:, :, ch]==cl, init_colors[cl][ch], im[:, :, ch])\n",
    "            \n",
    "    im = np.clip(im, 0, 255) / 255\n",
    "    return im\n",
    "\n",
    "\n",
    "def ohe_classes(im):\n",
    "    im = im[:, :, 0]\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for k in range(8):\n",
    "#     plt.imshow(a[k])\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model():\n",
    "    # Модель от Павла\n",
    "#     model = Unet('resnet34', \n",
    "#                                      input_shape=(IM_WIDTH, IM_HEIGHT, 3), \n",
    "#                                      intencoder_weights='imagenet', \n",
    "#                                      classes=6, activation='softmax')\n",
    "    \n",
    "    # Модель из нета с кропом\n",
    "    unet = UNet()\n",
    "    unet = unet.create_model(img_shape=(IM_WIDTH, IM_HEIGHT, 3), \n",
    "                  num_class=6)\n",
    "\n",
    "    return unet\n",
    "\n",
    "def train_model(model, epochs=100):\n",
    "    model.compile('Adam', \n",
    "#                  loss='categorical_crossentropy',\n",
    "                 loss='bce_jaccard_loss',\n",
    "#                  metrics=['categorical_accuracy']\n",
    "                 metrics=['iou_score']\n",
    "                )\n",
    "    \n",
    "    history = model.fit_generator(train_generator,\n",
    "                                  steps_per_epoch = 367 // BATCH_SIZE,\n",
    "                                 epochs=epochs,\n",
    "                                 verbose=2,\n",
    "                                 validation_data=test_generator,\n",
    "                                 validation_steps=101 // BATCH_SIZE,\n",
    "                                 workers=22,\n",
    "                                 )\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build UNet ...\n",
      "Epoch 1/100\n",
      " - 24s - loss: 1.6108 - iou_score: 0.0828 - val_loss: 1.4643 - val_iou_score: 0.1228\n",
      "Epoch 2/100\n",
      " - 20s - loss: 2.7414 - iou_score: 0.1190 - val_loss: 1.4395 - val_iou_score: 0.0567\n",
      "Epoch 3/100\n",
      " - 20s - loss: 1.3317 - iou_score: 0.1009 - val_loss: 1.5755 - val_iou_score: 0.0259\n",
      "Epoch 4/100\n",
      " - 20s - loss: 1.3847 - iou_score: 0.0969 - val_loss: 1.3107 - val_iou_score: 0.1151\n",
      "Epoch 5/100\n",
      " - 20s - loss: 1.5054 - iou_score: 0.1384 - val_loss: 1.4987 - val_iou_score: 0.1134\n",
      "Epoch 6/100\n",
      " - 20s - loss: 1.3407 - iou_score: 0.1045 - val_loss: 1.2566 - val_iou_score: 0.1262\n",
      "Epoch 7/100\n",
      " - 20s - loss: 1.6094 - iou_score: 0.1033 - val_loss: 1.3161 - val_iou_score: 0.1002\n",
      "Epoch 8/100\n",
      " - 20s - loss: 3.1440 - iou_score: 0.1105 - val_loss: 1.3580 - val_iou_score: 0.1013\n",
      "Epoch 9/100\n",
      " - 20s - loss: 2.3505 - iou_score: 0.0356 - val_loss: 1.3587 - val_iou_score: 0.1056\n",
      "Epoch 10/100\n",
      " - 19s - loss: 1.3664 - iou_score: 0.0954 - val_loss: 1.3620 - val_iou_score: 0.0901\n",
      "Epoch 11/100\n",
      " - 20s - loss: 1.3967 - iou_score: 0.0995 - val_loss: 1.5688 - val_iou_score: 0.0456\n",
      "Epoch 12/100\n",
      " - 20s - loss: 1.3545 - iou_score: 0.0934 - val_loss: 1.3474 - val_iou_score: 0.0975\n",
      "Epoch 13/100\n",
      " - 20s - loss: 1.3226 - iou_score: 0.0983 - val_loss: 1.3430 - val_iou_score: 0.0911\n",
      "Epoch 14/100\n",
      " - 20s - loss: 1.4141 - iou_score: 0.0952 - val_loss: 1.3523 - val_iou_score: 0.0837\n",
      "Epoch 15/100\n",
      " - 20s - loss: 1.3396 - iou_score: 0.1020 - val_loss: 1.3040 - val_iou_score: 0.1203\n",
      "Epoch 16/100\n",
      " - 20s - loss: 1.2931 - iou_score: 0.1157 - val_loss: 1.2751 - val_iou_score: 0.1311\n",
      "Epoch 17/100\n",
      " - 20s - loss: 1.4993 - iou_score: 0.1515 - val_loss: 1.8506 - val_iou_score: 0.1263\n",
      "Epoch 18/100\n",
      " - 20s - loss: 1.5040 - iou_score: 0.0641 - val_loss: 1.3818 - val_iou_score: 0.0817\n",
      "Epoch 19/100\n",
      " - 20s - loss: 1.3374 - iou_score: 0.0909 - val_loss: 1.3329 - val_iou_score: 0.0991\n",
      "Epoch 20/100\n",
      " - 20s - loss: 1.3245 - iou_score: 0.0988 - val_loss: 1.3036 - val_iou_score: 0.1091\n",
      "Epoch 21/100\n",
      " - 20s - loss: 3.8095 - iou_score: 0.1369 - val_loss: 10.4418 - val_iou_score: 0.2190\n",
      "Epoch 22/100\n",
      " - 20s - loss: 8.4741 - iou_score: 0.7245 - val_loss: 3.4330 - val_iou_score: 0.2202\n",
      "Epoch 23/100\n",
      " - 20s - loss: 3.4006 - iou_score: 0.2398 - val_loss: 3.4196 - val_iou_score: 0.2207\n",
      "Epoch 24/100\n",
      " - 20s - loss: 5.4319 - iou_score: 1.4018 - val_loss: 5.5521 - val_iou_score: 0.2207\n",
      "Epoch 25/100\n",
      " - 20s - loss: 5.1525 - iou_score: 0.2368 - val_loss: 5.5498 - val_iou_score: 0.2205\n",
      "Epoch 26/100\n",
      " - 20s - loss: 5.1177 - iou_score: 0.2384 - val_loss: 5.5494 - val_iou_score: 0.2211\n",
      "Epoch 27/100\n",
      " - 20s - loss: 5.1641 - iou_score: 0.2372 - val_loss: 5.5490 - val_iou_score: 0.2211\n",
      "Epoch 28/100\n",
      " - 20s - loss: 5.1358 - iou_score: 0.2427 - val_loss: 5.5867 - val_iou_score: 0.2237\n",
      "Epoch 29/100\n",
      " - 20s - loss: 4.0144 - iou_score: 1.8754 - val_loss: 9.6100 - val_iou_score: 0.2841\n",
      "Epoch 30/100\n",
      " - 20s - loss: 3.8861 - iou_score: 0.2796 - val_loss: 3.4332 - val_iou_score: 0.2205\n",
      "Epoch 31/100\n",
      " - 20s - loss: 3.4238 - iou_score: 0.2377 - val_loss: 3.4299 - val_iou_score: 0.2203\n",
      "Epoch 32/100\n",
      " - 20s - loss: 3.4082 - iou_score: 0.2441 - val_loss: 3.3996 - val_iou_score: 0.2534\n",
      "Epoch 33/100\n",
      " - 20s - loss: 5.1236 - iou_score: 0.1947 - val_loss: 5.5483 - val_iou_score: 0.2194\n",
      "Epoch 34/100\n",
      " - 20s - loss: 5.1309 - iou_score: 0.2367 - val_loss: 5.5512 - val_iou_score: 0.2226\n",
      "Epoch 35/100\n",
      " - 20s - loss: 5.6140 - iou_score: 0.2366 - val_loss: 5.5535 - val_iou_score: 0.2203\n",
      "Epoch 36/100\n",
      " - 20s - loss: 5.1271 - iou_score: 0.2376 - val_loss: 5.5540 - val_iou_score: 0.2207\n",
      "Epoch 37/100\n",
      " - 20s - loss: 5.1385 - iou_score: 0.2376 - val_loss: 5.5503 - val_iou_score: 0.2223\n",
      "Epoch 38/100\n",
      " - 20s - loss: 5.1347 - iou_score: 0.2483 - val_loss: 5.5283 - val_iou_score: 0.2419\n",
      "Epoch 39/100\n",
      " - 19s - loss: 7.5494 - iou_score: 0.3232 - val_loss: 10.4035 - val_iou_score: 0.2212\n",
      "Epoch 40/100\n",
      " - 20s - loss: 7.0508 - iou_score: 0.2385 - val_loss: 5.5483 - val_iou_score: 0.2216\n",
      "Epoch 41/100\n",
      " - 20s - loss: 7.2686 - iou_score: 0.2309 - val_loss: 10.3593 - val_iou_score: 0.2466\n",
      "Epoch 42/100\n",
      " - 20s - loss: 6.4492 - iou_score: 0.4297 - val_loss: 6.6504 - val_iou_score: 0.2207\n",
      "Epoch 43/100\n",
      " - 20s - loss: nan - iou_score: nan - val_loss: nan - val_iou_score: nan\n",
      "Epoch 44/100\n",
      " - 20s - loss: nan - iou_score: nan - val_loss: nan - val_iou_score: nan\n",
      "Epoch 45/100\n",
      " - 20s - loss: nan - iou_score: nan - val_loss: nan - val_iou_score: nan\n",
      "Epoch 46/100\n",
      " - 20s - loss: nan - iou_score: nan - val_loss: nan - val_iou_score: nan\n",
      "Epoch 47/100\n",
      " - 20s - loss: nan - iou_score: nan - val_loss: nan - val_iou_score: nan\n",
      "Epoch 48/100\n",
      " - 20s - loss: nan - iou_score: nan - val_loss: nan - val_iou_score: nan\n",
      "Epoch 49/100\n",
      " - 20s - loss: nan - iou_score: nan - val_loss: nan - val_iou_score: nan\n",
      "Epoch 50/100\n",
      " - 20s - loss: nan - iou_score: nan - val_loss: nan - val_iou_score: nan\n",
      "Epoch 51/100\n",
      " - 20s - loss: nan - iou_score: nan - val_loss: nan - val_iou_score: nan\n",
      "Epoch 52/100\n",
      " - 20s - loss: nan - iou_score: nan - val_loss: nan - val_iou_score: nan\n",
      "Epoch 53/100\n",
      " - 20s - loss: nan - iou_score: nan - val_loss: nan - val_iou_score: nan\n",
      "Epoch 54/100\n",
      " - 20s - loss: nan - iou_score: nan - val_loss: nan - val_iou_score: nan\n",
      "Epoch 55/100\n",
      " - 20s - loss: nan - iou_score: nan - val_loss: nan - val_iou_score: nan\n",
      "Epoch 56/100\n",
      " - 20s - loss: nan - iou_score: nan - val_loss: nan - val_iou_score: nan\n",
      "Epoch 57/100\n",
      " - 20s - loss: nan - iou_score: nan - val_loss: nan - val_iou_score: nan\n",
      "Epoch 58/100\n",
      " - 20s - loss: nan - iou_score: nan - val_loss: nan - val_iou_score: nan\n",
      "Epoch 59/100\n",
      " - 20s - loss: nan - iou_score: nan - val_loss: nan - val_iou_score: nan\n",
      "Epoch 60/100\n",
      " - 20s - loss: nan - iou_score: nan - val_loss: nan - val_iou_score: nan\n",
      "Epoch 61/100\n",
      " - 20s - loss: nan - iou_score: nan - val_loss: nan - val_iou_score: nan\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-e110a534fb5c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-23-2af2185b529b>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, epochs)\u001b[0m\n\u001b[0;32m     27\u001b[0m                                  \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m                                  \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m101\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m                                  \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m22\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m                                  )\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow_gpuenv\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow_gpuenv\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow_gpuenv\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[0;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m                                             class_weight=class_weight)\n\u001b[0m\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow_gpuenv\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1217\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1218\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow_gpuenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow_gpuenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2653\u001b[0m                 array_vals.append(\n\u001b[0;32m   2654\u001b[0m                     np.asarray(value,\n\u001b[1;32m-> 2655\u001b[1;33m                                dtype=tf.as_dtype(tensor.dtype).as_numpy_dtype))\n\u001b[0m\u001b[0;32m   2656\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2657\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow_gpuenv\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m     \"\"\"\n\u001b[1;32m--> 538\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = init_model()\n",
    "model = train_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'History' object has no attribute 'fit_generator'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-282f46d9a10d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m model.fit_generator(train_generator,\n\u001b[0m\u001b[0;32m      2\u001b[0m                                   \u001b[0msteps_per_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m367\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                                  \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                                  \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                  \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'History' object has no attribute 'fit_generator'"
     ]
    }
   ],
   "source": [
    "model.fit_generator(train_generator,\n",
    "                                  steps_per_epoch = 367 // BATCH_SIZE,\n",
    "                                 epochs=epochs,\n",
    "                                 verbose=2,\n",
    "                                 validation_data=test_generator,\n",
    "                                 validation_steps=101 // BATCH_SIZE,\n",
    "                                 workers=22,\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = init_model()\n",
    "# model.compile('Adam', \n",
    "#                  loss='categorical_crossentropy', \n",
    "#                  metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = model.fit_generator(generator=train_generator,\n",
    "#                                 steps_per_epoch=len(train_ims) // BATCH_SIZE,\n",
    "#                                 epochs=200,\n",
    "#                                 verbose=2,\n",
    "#                                 workers=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-43a08c0055ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m predict = model.predict_generator(test_generator,\n\u001b[0m\u001b[0;32m      2\u001b[0m                        steps=3)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "predict = model.predict_generator(test_generator,\n",
    "                       steps=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-275da24962ad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'predict' is not defined"
     ]
    }
   ],
   "source": [
    "predict = predict[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-477d4f4ed6da>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpredict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'predict' is not defined"
     ]
    }
   ],
   "source": [
    "predict[:, :, 0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
